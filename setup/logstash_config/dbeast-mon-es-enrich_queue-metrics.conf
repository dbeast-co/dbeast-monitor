input{
  http_poller {
    id => "Input-get-enrich-stats-from-ES"
    urls => {
      lab => "https://<HOST:PORT>/_enrich/_stats"
    }
	user => "dbeast-prod"
    password => "<PASSWORD>"

    request_timeout => 60
    schedule => { "cron" => "* * * * *"}
    codec => "json"

	ssl_verification_mode => "none"
    add_field => {
	  "[elasticsearch][cluster][id]" => "<YOUR-CLUSTER-ID>"
	  "[event][module]" => "elasticsearch"
	  "[event][dataset]" => "enrich_queue_stats"
	}	
  }
}
filter{
  mutate {
    id => "MUTATE-remove-and-rename-fields"
    remove_field => ["[event][original]", "executing_policies"]
	rename => {
      "coordinator_stats" => "[elasticsearch][node][stats][ingest][enrich][coordinator_stats]"
      "cache_stats" => "[elasticsearch][node][stats][ingest][enrich][cache_stats]"
    }
  }

  split {
    id => "SPLIT-Split-coordinator_stats"
    field => "[elasticsearch][node][stats][ingest][enrich][coordinator_stats]"
  } 

  split {
    id => "SPLIT-Split-cache_stats"
    field => "[elasticsearch][node][stats][ingest][enrich][cache_stats]"
  } 
  
  if !([elasticsearch][node][stats][ingest][enrich][cache_stats][node_id] in [elasticsearch][node][stats][ingest][enrich][coordinator_stats][node_id]){
    drop {
      id => "DROP-unnecessary-data"
    }
  }

  aggregate {
  	id => "AGGREGATE-calculate-rates"
    task_id => "%{[elasticsearch][cluster][id]}%{[elasticsearch][node][stats][ingest][enrich][coordinator_stats][node_id]}"
    code => "
	  require 'date';
	  #Date in seconds
	  sample_date = Time.now.to_i;
	  event.set('sample_date', sample_date);

      #Calculate rates
	  if map.key?('last_sample_date')
	    date_diff = ( sample_date - map['last_sample_date'] );
  	    #Calculate rates for processor
	    if event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_total]') > 0
	      event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_last_period]', (event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_total]') - map['last_executed_searches_total']));
	  	  event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_rate]', (event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_last_period]')/date_diff).ceil);
	  	  event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_last_period]', (event.get('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits]') - map['last_hits']));
	  	  event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_rate]', (event.get('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_last_period]')/date_diff).ceil);
	    else
	      event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_last_period]', 0);
	      event.set('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_rate]', 0);
	      event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_last_period]', 0);
	      event.set('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits_rate]', 0);
	    end
	    map['first_doc'] = false;
	  else
	    map['first_doc'] = true;
	  end

	  map['last_executed_searches_total'] = event.get('[elasticsearch][node][stats][ingest][enrich][coordinator_stats][executed_searches_total]').to_i;
	  map['last_hits'] = event.get('[elasticsearch][node][stats][ingest][enrich][cache_stats][hits]').to_i;
  	  map['last_sample_date'] =  sample_date;

	  #Drop document if there is no preview documents.
	  if map['first_doc']
	    event.cancel();
	  end
    "
    timeout => 3000000
    push_map_as_event_on_timeout => false
  }

  mutate {
    id => "MUTATE-Last-fields-update"
    rename => {
	  "[elasticsearch][node][stats][ingest][enrich][coordinator_stats][node_id]" => "[elasticsearch][node][id]"
    }
	remove_field => ["monitoring", "events", "[elasticsearch][node][stats][ingest][enrich][cache_stats][node_id]"]
  }

}
output{
  elasticsearch {
    id => "es-output-send-to-enrich-queue-historical-index"
	hosts => ["https://<HOST:PORT>"]
	user => "dbeast-mon"
	password => "<PASSWORD>"

	ssl => true
	ssl_certificate_verification => false
    index => "dbeast-mon-es-ingest_pipelines-%{+YYYY.MM.dd}"
	manage_template => false
  }
  elasticsearch {
    id => "es-output-send-to-enrich-queue-status-index"
	hosts => ["https://<HOST:PORT>"]
	user => "dbeast-mon"
	password => "<PASSWORD>"

	ssl => true
	ssl_certificate_verification => false
    index => "dbeast-mon-es-ingest_pipelines-status"
	manage_template => false
	document_id => "%{[elasticsearch][cluster][id]}-%{[elasticsearch][node][id]}"
  }

}
